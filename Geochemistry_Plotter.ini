import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from scipy.stats import pearsonr, spearmanr, kendalltau
import itertools
import os
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

class GeochemDataAnalyzer:
    def __init__(self):
        self.data = None
        self.numeric_columns = []
        self.type_column = None
        
    def load_data(self, file_path):
        """엑셀 또는 CSV 파일을 로드"""
        file_ext = Path(file_path).suffix.lower()
        
        if file_ext == '.xlsx':
            self.data = pd.read_excel(file_path)
        elif file_ext == '.csv':
            self.data = pd.read_csv(file_path)
        else:
            raise ValueError("지원되는 파일 형식: .xlsx, .csv")
        
        # 수치형 컬럼 식별
        self.numeric_columns = self.data.select_dtypes(include=[np.number]).columns.tolist()
        
        # 타입 컬럼 식별 (문자형 또는 카테고리형)
        potential_type_cols = self.data.select_dtypes(include=['object', 'category']).columns.tolist()
        if potential_type_cols:
            # 첫 번째 비수치형 컬럼을 타입 컬럼으로 사용 (사용자가 변경 가능)
            self.type_column = potential_type_cols[0]
        
        print(f"데이터 로드 완료: {self.data.shape[0]}행 x {self.data.shape[1]}열")
        print(f"수치형 컬럼: {len(self.numeric_columns)}개")
        if self.type_column:
            print(f"타입 컬럼: {self.type_column}")
    
    def set_type_column(self, column_name):
        """타입 컬럼 설정"""
        if column_name in self.data.columns:
            self.type_column = column_name
        else:
            raise ValueError(f"컬럼 '{column_name}'이 데이터에 없습니다.")
    
    def calculate_statistics(self, x_data, y_data, stat_methods=['pearson', 'spearman']):
        """통계 분석 수행"""
        results = {}
        
        # 결측값 제거
        mask = ~(np.isnan(x_data) | np.isnan(y_data))
        x_clean = x_data[mask]
        y_clean = y_data[mask]
        
        if len(x_clean) < 3:
            return {"error": "유효한 데이터 포인트가 부족합니다."}
        
        for method in stat_methods:
            if method == 'pearson':
                corr, p_val = pearsonr(x_clean, y_clean)
                results['pearson_corr'] = corr
                results['pearson_p'] = p_val
            elif method == 'spearman':
                corr, p_val = spearmanr(x_clean, y_clean)
                results['spearman_corr'] = corr
                results['spearman_p'] = p_val
            elif method == 'kendall':
                corr, p_val = kendalltau(x_clean, y_clean)
                results['kendall_corr'] = corr
                results['kendall_p'] = p_val
        
        # R-squared (선형 회귀)
        if len(x_clean) > 2:
            slope, intercept, r_value, p_value, std_err = stats.linregress(x_clean, y_clean)
            results['r_squared'] = r_value**2
            results['linear_slope'] = slope
            results['linear_intercept'] = intercept
        
        return results
    
    def create_scatter_plot(self, x_col, y_col, x_range=None, y_range=None, 
                          title=None, save_path=None, figsize=(10, 8)):
        """산점도 생성"""
        fig, ax = plt.subplots(figsize=figsize)
        
        # 데이터 준비
        plot_data = self.data[[x_col, y_col]].copy()
        if self.type_column:
            plot_data['type'] = self.data[self.type_column]
        
        # 결측값 제거
        plot_data = plot_data.dropna()
        
        if self.type_column and 'type' in plot_data.columns:
            # 타입별로 다른 스타일로 그리기
            unique_types = plot_data['type'].unique()
            colors = plt.cm.Set1(np.linspace(0, 1, len(unique_types)))
            markers = ['o', 's', '^', 'D', 'v', '<', '>', 'p', '*', 'h']
            
            for i, type_val in enumerate(unique_types):
                mask = plot_data['type'] == type_val
                ax.scatter(plot_data.loc[mask, x_col], 
                          plot_data.loc[mask, y_col],
                          c=[colors[i]], 
                          marker=markers[i % len(markers)],
                          s=60, alpha=0.7, label=str(type_val))
            
            ax.legend(title=self.type_column, bbox_to_anchor=(1.05, 1), loc='upper left')
        else:
            # 단일 스타일로 그리기
            ax.scatter(plot_data[x_col], plot_data[y_col], 
                      alpha=0.6, s=50, c='blue')
        
        # 축 범위 설정
        if x_range:
            ax.set_xlim(x_range)
        if y_range:
            ax.set_ylim(y_range)
        
        # 라벨 및 제목
        ax.set_xlabel(x_col)
        ax.set_ylabel(y_col)
        ax.set_title(title or f'{x_col} vs {y_col}')
        
        # 격자 추가
        ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        # 저장
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            # SVG로도 저장
            svg_path = save_path.replace('.png', '.svg')
            plt.savefig(svg_path, format='svg', bbox_inches='tight')
        
        return fig, ax
    
    def full_scan_mode(self, stat_methods=['pearson'], threshold=0.5, p_threshold=0.05, 
                      save_dir='output'):
        """전체 스캔 모드: 모든 가능한 조합 분석"""
        if not os.path.exists(save_dir):
            os.makedirs(save_dir)
        
        results = []
        combinations = list(itertools.combinations(self.numeric_columns, 2))
        
        print(f"총 {len(combinations)}개 조합 분석 중...")
        
        for i, (col1, col2) in enumerate(combinations):
            print(f"진행률: {i+1}/{len(combinations)} - {col1} vs {col2}")
            
            # 통계 분석
            x_data = self.data[col1].values
            y_data = self.data[col2].values
            
            stats_result = self.calculate_statistics(x_data, y_data, stat_methods)
            
            if 'error' not in stats_result:
                # 조건 확인
                meets_criteria = False
                for method in stat_methods:
                    corr_key = f'{method}_corr'
                    p_key = f'{method}_p'
                    
                    if corr_key in stats_result and p_key in stats_result:
                        if (abs(stats_result[corr_key]) >= threshold and 
                            stats_result[p_key] <= p_threshold):
                            meets_criteria = True
                            break
                
                result_dict = {
                    'x_variable': col1,
                    'y_variable': col2,
                    'meets_criteria': meets_criteria,
                    **stats_result
                }
                results.append(result_dict)
                
                # 조건을 만족하는 경우 그래프 저장
                if meets_criteria:
                    save_path = os.path.join(save_dir, f"{col1}_vs_{col2}.png")
                    self.create_scatter_plot(col1, col2, save_path=save_path)
                    plt.close()
        
        # 결과를 DataFrame으로 변환
        results_df = pd.DataFrame(results)
        
        # 조건을 만족하는 결과만 필터링
        significant_results = results_df[results_df['meets_criteria'] == True]
        
        # 결과 저장
        results_df.to_csv(os.path.join(save_dir, 'all_combinations_results.csv'), index=False)
        significant_results.to_csv(os.path.join(save_dir, 'significant_combinations.csv'), index=False)
        
        print(f"\n분석 완료!")
        print(f"전체 조합: {len(results_df)}개")
        print(f"유의한 조합: {len(significant_results)}개")
        
        return significant_results
    
    def selective_mode(self, x_col, y_col, x_range=None, y_range=None, 
                      stat_methods=['pearson', 'spearman'], save_path=None):
        """선택 모드: 특정 두 변수 분석"""
        if x_col not in self.numeric_columns or y_col not in self.numeric_columns:
            raise ValueError("선택한 컬럼이 수치형이 아닙니다.")
        
        # 그래프 생성
        fig, ax = self.create_scatter_plot(x_col, y_col, x_range, y_range, save_path=save_path)
        
        # 통계 분석
        x_data = self.data[x_col].values
        y_data = self.data[y_col].values
        stats_result = self.calculate_statistics(x_data, y_data, stat_methods)
        
        # 결과 출력
        print(f"\n=== {x_col} vs {y_col} 분석 결과 ===")
        for key, value in stats_result.items():
            if 'error' not in key:
                print(f"{key}: {value:.4f}")
        
        plt.show()
        
        return stats_result, fig

# 사용 예시
def main():
    # 분석기 초기화
    analyzer = GeochemDataAnalyzer()
    
    # 데이터 로드 (파일 경로를 실제 경로로 변경하세요)
    # analyzer.load_data('your_geochem_data.xlsx')
    
    # 타입 컬럼 설정 (필요한 경우)
    # analyzer.set_type_column('rock_type')
    
    # 선택 모드 사용 예시
    # stats, fig = analyzer.selective_mode('SiO2', 'Al2O3', 
    #                                     x_range=[40, 80], 
    #                                     y_range=[10, 20],
    #                                     save_path='SiO2_vs_Al2O3.png')
    
    # 전체 스캔 모드 사용 예시
    # significant_results = analyzer.full_scan_mode(
    #     stat_methods=['pearson', 'spearman'],
    #     threshold=0.7,
    #     p_threshold=0.01,
    #     save_dir='geochem_analysis_results'
    # )
    
    pass

if __name__ == "__main__":
    main()
    
    # 테스트용 샘플 데이터 생성 및 분석기 테스트
    print("=== GeochemDataAnalyzer 테스트 시작 ===\n")
    
    # 테스트용 지구화학 데이터 생성
    import numpy as np
    import pandas as pd
    
    # 실제 지구화학 데이터와 유사한 샘플 데이터 생성
    np.random.seed(42)
    n_samples = 100
    
    # 암석 타입별 특성이 있는 데이터 생성
    rock_types = ['granite', 'basalt', 'andesite', 'dacite']
    data = {
        'rock_type': np.random.choice(rock_types, n_samples),
        'SiO2': np.random.normal(60, 15, n_samples),
        'Al2O3': np.random.normal(15, 3, n_samples),
        'Fe2O3': np.random.normal(8, 4, n_samples),
        'MgO': np.random.normal(5, 3, n_samples),
        'CaO': np.random.normal(6, 2, n_samples),
        'Na2O': np.random.normal(3, 1, n_samples),
        'K2O': np.random.normal(2, 1, n_samples),
        'TiO2': np.random.normal(1, 0.5, n_samples)
    }
    
    # 음수값 제거 (지구화학 데이터는 양수여야 함)
    for col in data.keys():
        if col != 'rock_type':
            data[col] = np.abs(data[col])
    
    # SiO2와 Al2O3 간 상관관계 추가
    data['Al2O3'] = data['Al2O3'] + 0.3 * (data['SiO2'] - 60) + np.random.normal(0, 1, n_samples)
    data['Al2O3'] = np.abs(data['Al2O3'])
    
    test_df = pd.DataFrame(data)
    
    # 분석기 초기화 및 데이터 로드
    analyzer = GeochemDataAnalyzer()
    analyzer.data = test_df
    analyzer.set_type_column('rock_type')
    
    print("1. 생성된 테스트 데이터 정보:")
    print(f"   - 샘플 수: {len(test_df)}")
    print(f"   - 컬럼: {list(test_df.columns)}")
    print(f"   - 암석 타입: {test_df['rock_type'].unique()}")
    print()
    
    # 테스트 1: 선택 모드 테스트
    print("2. 선택 모드 테스트 (SiO2 vs Al2O3):")
    try:
        stats, fig = analyzer.selective_mode('SiO2', 'Al2O3', 
                                           stat_methods=['pearson', 'spearman'])
        print("   ✓ 선택 모드 테스트 성공")
    except Exception as e:
        print(f"   ✗ 선택 모드 테스트 실패: {e}")
    print()
    
    # 테스트 2: 전체 스캔 모드 테스트
    print("3. 전체 스캔 모드 테스트:")
    try:
        significant_results = analyzer.full_scan_mode(
            stat_methods=['pearson'],
            threshold=0.3,
            p_threshold=0.05
        )
        print(f"   ✓ 전체 스캔 모드 테스트 성공")
        print(f"   - 유의한 상관관계 발견: {len(significant_results)}개")
    except Exception as e:
        print(f"   ✗ 전체 스캔 모드 테스트 실패: {e}")
    print()
    
    print("=== 테스트 완료 ===")
    print("실제 데이터를 사용하려면:")
    print("1. analyzer.load_data('your_file.xlsx') 로 데이터 로드")
    print("2. analyzer.set_type_column('your_type_column') 로 타입 컬럼 설정")
    print("3. 위의 예시 코드들을 주석 해제하여 사용")
