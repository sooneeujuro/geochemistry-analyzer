import * as ss from 'simple-statistics'
import { StatisticalResult, PCAResult, PCASuggestion } from '@/types/geochem'

// ML-Matrix import (íƒ€ì… ì„ ì–¸ ì—†ìŒ)
const { Matrix, EVD } = require('ml-matrix')

export function calculateStatistics(
  xData: number[],
  yData: number[],
  statMethods: ('pearson' | 'spearman' | 'kendall')[] = ['pearson', 'spearman']
): StatisticalResult {
  try {
    // ê²°ì¸¡ê°’ ì œê±°
    const validPairs = xData
      .map((x, i) => ({ x, y: yData[i] }))
      .filter(pair => !isNaN(pair.x) && !isNaN(pair.y) && isFinite(pair.x) && isFinite(pair.y))
    
    if (validPairs.length < 3) {
      return { error: "ìœ íš¨í•œ ë°ì´í„° í¬ì¸íŠ¸ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤." }
    }
    
    const xClean = validPairs.map(p => p.x)
    const yClean = validPairs.map(p => p.y)
    
    const results: StatisticalResult = {}
    
    // í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜
    if (statMethods.includes('pearson')) {
      try {
        const pearsonCorr = ss.sampleCorrelation(xClean, yClean)
        results.pearsonCorr = pearsonCorr
        
        // p-ê°’ ê·¼ì‚¬ ê³„ì‚° (t-test)
        const n = xClean.length
        const t = pearsonCorr * Math.sqrt((n - 2) / (1 - pearsonCorr * pearsonCorr))
        results.pearsonP = calculateTTestPValue(t, n - 2)
      } catch (e) {
        console.warn('Pearson correlation calculation failed:', e)
      }
    }
    
    // ìŠ¤í”¼ì–´ë§Œ ìƒê´€ê³„ìˆ˜ (ìˆœìœ„ ê¸°ë°˜)
    if (statMethods.includes('spearman')) {
      try {
        const xRanks = getRanks(xClean)
        const yRanks = getRanks(yClean)
        const spearmanCorr = ss.sampleCorrelation(xRanks, yRanks)
        results.spearmanCorr = spearmanCorr
        
        // p-ê°’ ê·¼ì‚¬ ê³„ì‚°
        const n = xClean.length
        const t = spearmanCorr * Math.sqrt((n - 2) / (1 - spearmanCorr * spearmanCorr))
        results.spearmanP = calculateTTestPValue(t, n - 2)
      } catch (e) {
        console.warn('Spearman correlation calculation failed:', e)
      }
    }
    
    // ì„ í˜• íšŒê·€
    if (xClean.length > 2) {
      try {
        // simple-statistics í˜•ì‹ì— ë§ê²Œ [[x1, y1], [x2, y2], ...] ë°°ì—´ë¡œ ë³€í™˜
        const regressionData = validPairs.map(point => [point.x, point.y])
        const regression = ss.linearRegression(regressionData)
        const regressionLine = ss.linearRegressionLine(regression)
        const rSquared = ss.rSquared(regressionData, regressionLine)
        
        results.rSquared = rSquared
        results.linearSlope = regression.m
        results.linearIntercept = regression.b
      } catch (e) {
        console.warn('Linear regression calculation failed:', e)
      }
    }
    
    return results
  } catch (error) {
    return { error: `í†µê³„ ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: ${error}` }
  }
}

// ìˆœìœ„ ê³„ì‚° í•¨ìˆ˜
function getRanks(data: number[]): number[] {
  const sorted = [...data]
    .map((value, index) => ({ value, index }))
    .sort((a, b) => a.value - b.value)
  
  const ranks = new Array(data.length)
  
  for (let i = 0; i < sorted.length; i++) {
    ranks[sorted[i].index] = i + 1
  }
  
  return ranks
}

// t-ë¶„í¬ p-ê°’ ê³„ì‚° (regularized incomplete beta function ì‚¬ìš©)
function calculateTTestPValue(t: number, df: number): number {
  const absT = Math.abs(t)
  const x = df / (df + absT * absT)

  // Regularized incomplete beta function ê·¼ì‚¬ (Lentz's continued fraction algorithm)
  const betaIncomplete = (a: number, b: number, x: number): number => {
    if (x === 0) return 0
    if (x === 1) return 1

    // Lanczos approximation for beta function
    const lnBeta = (a: number, b: number): number => {
      const lnGamma = (z: number): number => {
        const g = 7
        const coefficients = [
          0.99999999999980993,
          676.5203681218851,
          -1259.1392167224028,
          771.32342877765313,
          -176.61502916214059,
          12.507343278686905,
          -0.13857109526572012,
          9.9843695780195716e-6,
          1.5056327351493116e-7
        ]

        if (z < 0.5) {
          return Math.log(Math.PI / Math.sin(Math.PI * z)) - lnGamma(1 - z)
        }

        z -= 1
        let x = coefficients[0]
        for (let i = 1; i < g + 2; i++) {
          x += coefficients[i] / (z + i)
        }
        const t = z + g + 0.5
        return 0.5 * Math.log(2 * Math.PI) + (z + 0.5) * Math.log(t) - t + Math.log(x)
      }

      return lnGamma(a) + lnGamma(b) - lnGamma(a + b)
    }

    // Continued fraction approximation
    const maxIterations = 200
    const epsilon = 1e-10

    let c = 1
    let d = 1 - (a + b) * x / (a + 1)
    if (Math.abs(d) < epsilon) d = epsilon
    d = 1 / d
    let h = d

    for (let m = 1; m <= maxIterations; m++) {
      const m2 = 2 * m

      // Even step
      let an = m * (b - m) * x / ((a + m2 - 1) * (a + m2))
      d = 1 + an * d
      if (Math.abs(d) < epsilon) d = epsilon
      c = 1 + an / c
      if (Math.abs(c) < epsilon) c = epsilon
      d = 1 / d
      h *= d * c

      // Odd step
      an = -(a + m) * (a + b + m) * x / ((a + m2) * (a + m2 + 1))
      d = 1 + an * d
      if (Math.abs(d) < epsilon) d = epsilon
      c = 1 + an / c
      if (Math.abs(c) < epsilon) c = epsilon
      d = 1 / d
      const del = d * c
      h *= del

      if (Math.abs(del - 1) < epsilon) break
    }

    const lnBetaVal = lnBeta(a, b)
    const result = Math.exp(a * Math.log(x) + b * Math.log(1 - x) - lnBetaVal) * h / a

    return Math.min(1, Math.max(0, result))
  }

  // Two-tailed p-value from t-distribution
  const pValue = betaIncomplete(df / 2, 0.5, x)
  return Math.min(1, Math.max(0, pValue))
}

// ì „ì²´ ìŠ¤ìº” ë¶„ì„ í•¨ìˆ˜
export function performFullScanAnalysis(
  data: Record<string, any>[],
  numericColumns: string[],
  threshold: number = 0.5,
  pThreshold: number = 0.05,
  statMethods: ('pearson' | 'spearman' | 'kendall')[] = ['pearson']
) {
  const results: Array<{
    xVariable: string
    yVariable: string
    meetsQriteria: boolean
  } & StatisticalResult> = []
  
  // ëª¨ë“  ê°€ëŠ¥í•œ ì¡°í•© ìƒì„±
  for (let i = 0; i < numericColumns.length; i++) {
    for (let j = i + 1; j < numericColumns.length; j++) {
      const col1 = numericColumns[i]
      const col2 = numericColumns[j]
      
      const xData = data.map(row => parseFloat(row[col1])).filter(val => !isNaN(val))
      const yData = data.map(row => parseFloat(row[col2])).filter(val => !isNaN(val))
      
      const stats = calculateStatistics(xData, yData, statMethods)
      
      if (!stats.error) {
        const meetsQriteria = statMethods.some(method => {
          const corrKey = `${method}Corr` as keyof StatisticalResult
          const pKey = `${method}P` as keyof StatisticalResult
          const corr = stats[corrKey] as number
          const p = stats[pKey] as number
          
          return Math.abs(corr) >= threshold && p <= pThreshold
        })
        
        results.push({
          xVariable: col1,
          yVariable: col2,
          meetsQriteria,
          ...stats
        })
      }
    }
  }
  
  return results.filter(result => result.meetsQriteria)
}

// í—¬í¼ í•¨ìˆ˜ë“¤
function calculateSkewness(data: number[], mean: number, stdDev: number): number {
  const n = data.length
  const m3 = data.reduce((sum, x) => sum + Math.pow((x - mean) / stdDev, 3), 0) / n
  return m3
}

function calculateKurtosis(data: number[], mean: number, stdDev: number): number {
  const n = data.length
  const m4 = data.reduce((sum, x) => sum + Math.pow((x - mean) / stdDev, 4), 0) / n
  return m4 - 3 // excess kurtosis
}

// ê³ ê¸‰ í†µê³„ë¶„ì„ ê¸°ëŠ¥ë“¤
export interface AdvancedStatistics {
  mean: number
  median: number
  standardDeviation: number
  variance: number
  skewness: number
  kurtosis: number
  quantiles: {
    q25: number
    q75: number
  }
  outliers: number[]
  normality: {
    shapiroWilk?: number
    isNormal: boolean
  }
}

export interface RegressionAnalysis {
  model: 'linear' | 'polynomial' | 'multiple'
  coefficients: number[]
  rSquared: number
  adjustedRSquared: number
  fStatistic: number
  pValue: number
  residuals: number[]
  predicted: number[]
}

// ê¸°ìˆ í†µê³„ ê³„ì‚°
export function calculateDescriptiveStats(data: number[]): AdvancedStatistics {
  const cleanData = data.filter(x => !isNaN(x) && isFinite(x))
  
  if (cleanData.length === 0) {
    throw new Error('No valid data points')
  }

  // ê¸°ë³¸ í†µê³„ëŸ‰
  const meanVal = ss.mean(cleanData)
  const medianVal = ss.median(cleanData)
  const stdDev = ss.standardDeviation(cleanData)
  const varianceVal = ss.variance(cleanData)
  
  // ë¶„í¬ í˜•íƒœ (ì§ì ‘ ê³„ì‚°)
  const skewnessVal = calculateSkewness(cleanData, meanVal, stdDev)
  const kurtosisVal = calculateKurtosis(cleanData, meanVal, stdDev)
  
  // ì‚¬ë¶„ìœ„ìˆ˜
  const q25 = ss.quantile(cleanData, 0.25)
  const q75 = ss.quantile(cleanData, 0.75)
  
  // ì´ìƒì¹˜ íƒì§€ (IQR ë°©ë²•)
  const iqr = q75 - q25
  const lowerBound = q25 - 1.5 * iqr
  const upperBound = q75 + 1.5 * iqr
  const outliers = cleanData.filter(x => x < lowerBound || x > upperBound)
  
  // ì •ê·œì„± ê²€ì • (ê°„ë‹¨í•œ ê·¼ì‚¬)
  const isNormal = Math.abs(skewnessVal) < 1 && Math.abs(kurtosisVal) < 3
  
  return {
    mean: meanVal,
    median: medianVal,
    standardDeviation: stdDev,
    variance: varianceVal,
    skewness: skewnessVal,
    kurtosis: kurtosisVal,
    quantiles: { q25, q75 },
    outliers,
    normality: { isNormal }
  }
}

// ìƒê´€ê´€ê³„ ë§¤íŠ¸ë¦­ìŠ¤ ê³„ì‚°
export function calculateCorrelationMatrix(data: Record<string, number[]>): Record<string, Record<string, number>> {
  const variables = Object.keys(data)
  const matrix: Record<string, Record<string, number>> = {}
  
  variables.forEach(var1 => {
    matrix[var1] = {}
    variables.forEach(var2 => {
      if (var1 === var2) {
        matrix[var1][var2] = 1
      } else {
        try {
          const corr = ss.sampleCorrelation(data[var1], data[var2])
          matrix[var1][var2] = isNaN(corr) ? 0 : corr
        } catch {
          matrix[var1][var2] = 0
        }
      }
    })
  })
  
  return matrix
}

// PCA ì¶”ì²œ ë¡œì§
export function suggestPCAVariables(
  correlationMatrix: number[][],
  variableNames: string[],
  threshold: number = 0.6
): PCASuggestion[] {
  const suggestions: PCASuggestion[] = []
  
  // ìƒê´€ê´€ê³„ê°€ ë†’ì€ ë³€ìˆ˜ ê·¸ë£¹ ì°¾ê¸°
  const groups: string[][] = []
  const used = new Set<string>()
  
  for (let i = 0; i < variableNames.length; i++) {
    if (used.has(variableNames[i])) continue
    
    const group = [variableNames[i]]
    used.add(variableNames[i])
    
    for (let j = i + 1; j < variableNames.length; j++) {
      if (used.has(variableNames[j])) continue
      
      // ê·¸ë£¹ ë‚´ ëª¨ë“  ë³€ìˆ˜ì™€ì˜ í‰ê·  ìƒê´€ê³„ìˆ˜ ê³„ì‚°
      let totalCorr = 0
      let count = 0
      
      for (const groupVar of group) {
        const groupIdx = variableNames.indexOf(groupVar)
        totalCorr += Math.abs(correlationMatrix[groupIdx][j])
        count++
      }
      
      const avgCorr = totalCorr / count
      if (avgCorr >= threshold) {
        group.push(variableNames[j])
        used.add(variableNames[j])
      }
    }
    
    if (group.length >= 3) { // ìµœì†Œ 3ê°œ ë³€ìˆ˜ ì´ìƒì¸ ê·¸ë£¹ë§Œ
      groups.push(group)
    }
  }
  
  // ê° ê·¸ë£¹ì— ëŒ€í•´ PCA ì¶”ì²œ ìƒì„± (ê°œì„ ëœ ë¡œì§)
  groups.forEach((group, index) => {
    // ê·¸ë£¹ ë‚´ì—ì„œ ê°€ì¥ ëŒ€í‘œì ì¸ ë³€ìˆ˜ë“¤ ì„ ì • (ìµœëŒ€ 6ê°œ)
    const sortedByVariance = group.sort((a, b) => {
      const aIdx = variableNames.indexOf(a)
      const bIdx = variableNames.indexOf(b)
      
      // ë‹¤ë¥¸ ë³€ìˆ˜ë“¤ê³¼ì˜ í‰ê·  ìƒê´€ê³„ìˆ˜ë¡œ ì •ë ¬ (ë†’ì€ ìˆœ)
      const aAvgCorr = correlationMatrix[aIdx].reduce((sum, corr, idx) => {
        if (idx !== aIdx && group.includes(variableNames[idx])) {
          return sum + Math.abs(corr)
        }
        return sum
      }, 0) / (group.length - 1)
      
      const bAvgCorr = correlationMatrix[bIdx].reduce((sum, corr, idx) => {
        if (idx !== bIdx && group.includes(variableNames[idx])) {
          return sum + Math.abs(corr)
        }
        return sum
      }, 0) / (group.length - 1)
      
      return bAvgCorr - aAvgCorr
    })
    
    const selectedVariables = sortedByVariance.slice(0, 6) // ìµœëŒ€ 6ê°œ
    
    // ê°€ìƒ PCA ê²€ì¦: ìµœì†Œ 2ê°œ ì»´í¬ë„ŒíŠ¸ê°€ ì˜ë¯¸ìˆëŠ”ì§€ í™•ì¸
    const avgCorrelation = selectedVariables.reduce((sum, var1, i) => {
      return sum + selectedVariables.slice(i + 1).reduce((innerSum, var2) => {
        const idx1 = variableNames.indexOf(var1)
        const idx2 = variableNames.indexOf(var2)
        return innerSum + Math.abs(correlationMatrix[idx1][idx2])
      }, 0)
    }, 0) / (selectedVariables.length * (selectedVariables.length - 1) / 2)
    
    // ìƒê´€ê´€ê³„ ê°•ë„ì— ë”°ë¥¸ ì˜ˆìƒ ë¶„ì‚° ì„¤ëª…ë ¥ ì¶”ì • (ê°œì„ ëœ ê³µì‹)
    const estimatedPC1Variance = Math.min(avgCorrelation * 50 + 40, 80) // 40-80% ë²”ìœ„
    const estimatedPC2Variance = Math.max(30 - avgCorrelation * 15, 10) // 10-30% ë²”ìœ„
    
    // PC2ê°€ ìµœì†Œ 10% ì´ìƒì˜ ë¶„ì‚°ì„ ì„¤ëª…í•  ìˆ˜ ìˆëŠ” ê²½ìš°ë§Œ ì¶”ì²œ
    if (estimatedPC2Variance >= 10) {
      const varianceExplained = estimatedPC1Variance + estimatedPC2Variance
      
      // ì‹ ë¢°ë„ ê³„ì‚°: ìƒê´€ê´€ê³„ ê°•ë„, PC2 ì„¤ëª…ë ¥, ë³€ìˆ˜ ìˆ˜ì˜ ê· í˜•ì„ ê³ ë ¤
      const correlationScore = Math.min(avgCorrelation, 1) // 0-1 ë²”ìœ„
      const pc2Score = Math.min(estimatedPC2Variance / 30, 1) // 30%ë¥¼ ë§Œì ìœ¼ë¡œ 0-1 ë²”ìœ„
      const variableCountScore = Math.min((selectedVariables.length - 2) / 4, 1) // 2-6ê°œ ë³€ìˆ˜ ë²”ìœ„ì—ì„œ 0-1
      
      const confidence = (correlationScore * 0.4 + pc2Score * 0.4 + variableCountScore * 0.2)
      
      suggestions.push({
        variables: selectedVariables,
        reason: `${selectedVariables.length}ê°œ ë³€ìˆ˜ê°€ ë†’ì€ ìƒê´€ê´€ê³„ (í‰ê·  r=${avgCorrelation.toFixed(2)})ë¥¼ ë³´ì„. PC1ì€ ${estimatedPC1Variance.toFixed(0)}%, PC2ëŠ” ${estimatedPC2Variance.toFixed(0)}%ì˜ ë¶„ì‚° ì„¤ëª… ì˜ˆìƒ.`,
        expectedVariance: varianceExplained,
        correlation: avgCorrelation,
        confidence: confidence
      })
    }
  })
  
  // ë¶„ì‚° ì„¤ëª…ë ¥ê³¼ ìƒê´€ê³„ìˆ˜ë¥¼ ì¢…í•©í•œ ì ìˆ˜ë¡œ ì •ë ¬
  suggestions.sort((a, b) => {
    const scoreA = a.expectedVariance * 0.7 + a.correlation * 30
    const scoreB = b.expectedVariance * 0.7 + b.correlation * 30
    return scoreB - scoreA
  })
  
  return suggestions.slice(0, 3) // ìƒìœ„ 3ê°œë§Œ ë°˜í™˜
}

// PCA ê³„ì‚° í•¨ìˆ˜ (pca-js ì‚¬ìš©)
export function performPCA(
  data: Record<string, any>[],
  variableNames: string[],
  nComponents?: number
): PCAResult {
  try {
    // ë°ì´í„° ì¤€ë¹„: ë³€ìˆ˜ë³„ë¡œ ìˆ«ì ë°ì´í„°ë§Œ ì¶”ì¶œí•˜ê³  ê²°ì¸¡ê°’ ì œê±°
    const cleanData: number[][] = []
    const invalidRows: number[] = []
    
    data.forEach((row, rowIndex) => {
      const values = variableNames.map(name => {
        const val = row[name]
        // ë” ê´€ëŒ€í•œ ìˆ«ì ë³€í™˜ ì‹œë„
        if (typeof val === 'string' && val.trim() !== '') {
          const parsed = parseFloat(val.trim())
          return !isNaN(parsed) && isFinite(parsed) ? parsed : null
        }
        return typeof val === 'number' && !isNaN(val) && isFinite(val) ? val : null
      })
      
      // ì™„í™”ëœ ì¡°ê±´: ìµœì†Œ 80%ì˜ ë³€ìˆ˜ê°€ ìœ íš¨í•˜ë©´ í¬í•¨ (ë‹¨, ìµœì†Œ 2ê°œ ë³€ìˆ˜ëŠ” í•„ìš”)
      const validCount = values.filter(val => val !== null).length
      const minRequiredValid = Math.max(2, Math.ceil(variableNames.length * 0.8))
      
      if (validCount >= minRequiredValid) {
        // ê²°ì¸¡ê°’ì„ í•´ë‹¹ ë³€ìˆ˜ì˜ í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´
        const filledValues = values.map((val, varIndex) => {
          if (val !== null) return val
          
          // í•´ë‹¹ ë³€ìˆ˜ì˜ ìœ íš¨í•œ ê°’ë“¤ì˜ í‰ê·  ê³„ì‚°
          const varName = variableNames[varIndex]
          const validValues = data
            .map(r => {
              const v = r[varName]
              if (typeof v === 'string' && v.trim() !== '') {
                const parsed = parseFloat(v.trim())
                return !isNaN(parsed) && isFinite(parsed) ? parsed : null
              }
              return typeof v === 'number' && !isNaN(v) && isFinite(v) ? v : null
            })
            .filter(v => v !== null) as number[]
          
          // í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´ (ìœ íš¨í•œ ê°’ì´ ì—†ìœ¼ë©´ 0ìœ¼ë¡œ ëŒ€ì²´)
          return validValues.length > 0 
            ? validValues.reduce((sum, v) => sum + v, 0) / validValues.length 
            : 0
        })
        
        cleanData.push(filledValues)
      } else {
        invalidRows.push(rowIndex)
      }
    })

    // ë³€ìˆ˜ë³„ ìœ íš¨ ë°ì´í„° ê°œìˆ˜ í™•ì¸
    const variableValidCounts = variableNames.map(name => {
      const validCount = data.filter(row => {
        const val = row[name]
        if (typeof val === 'string' && val.trim() !== '') {
          const parsed = parseFloat(val.trim())
          return !isNaN(parsed) && isFinite(parsed)
        }
        return typeof val === 'number' && !isNaN(val) && isFinite(val)
      }).length
      return { variable: name, validCount, totalCount: data.length }
    })

    if (cleanData.length < 3) {
      const errorDetails = `
PCA ë¶„ì„ì— í•„ìš”í•œ ìœ íš¨ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.

ğŸ“Š ë°ì´í„° í˜„í™©:
â€¢ ì „ì²´ í–‰ ìˆ˜: ${data.length}ê°œ
â€¢ ìœ íš¨ í–‰ ìˆ˜: ${cleanData.length}ê°œ 
â€¢ í•„ìš”í•œ ìµœì†Œ í–‰ ìˆ˜: 3ê°œ

ğŸ” ë³€ìˆ˜ë³„ ìœ íš¨ ë°ì´í„°:
${variableValidCounts.map(v => `â€¢ ${v.variable}: ${v.validCount}/${v.totalCount}ê°œ`).join('\n')}

ğŸ’¡ í•´ê²° ë°©ë²•:
1. ê²°ì¸¡ê°’ì´ ì ì€ ë³€ìˆ˜ë“¤ì„ ì„ íƒí•´ë³´ì„¸ìš”
2. ë°ì´í„°ì— ìˆ«ìê°€ ì•„ë‹Œ ê°’(í…ìŠ¤íŠ¸, ë¹ˆ ì¹¸)ì´ ìˆëŠ”ì§€ í™•ì¸í•´ë³´ì„¸ìš”
3. ë” ë§ì€ ë°ì´í„°ê°€ í¬í•¨ëœ íŒŒì¼ì„ ì‚¬ìš©í•´ë³´ì„¸ìš”`

      throw new Error(errorDetails)
    }
    
    if (variableNames.length < 2) {
      throw new Error('PCAë¥¼ ìˆ˜í–‰í•˜ê¸°ì— ë³€ìˆ˜ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. (ìµœì†Œ 2ê°œ ë³€ìˆ˜ í•„ìš”)')
    }
    
    // ë°ì´í„° í‘œì¤€í™” (í‰ê·  0, ë¶„ì‚° 1)
    const means = new Array(variableNames.length).fill(0)
    const stds = new Array(variableNames.length).fill(0)
    
    // í‰ê·  ê³„ì‚°
    for (let j = 0; j < variableNames.length; j++) {
      means[j] = cleanData.reduce((sum, row) => sum + row[j], 0) / cleanData.length
    }
    
    // í‘œì¤€í¸ì°¨ ê³„ì‚°
    for (let j = 0; j < variableNames.length; j++) {
      const variance = cleanData.reduce((sum, row) => sum + Math.pow(row[j] - means[j], 2), 0) / (cleanData.length - 1)
      stds[j] = Math.sqrt(variance)
    }
    
    // ë°ì´í„° í‘œì¤€í™”
    const standardizedData = cleanData.map(row => 
      row.map((val, j) => stds[j] > 0 ? (val - means[j]) / stds[j] : 0)
    )
    
    // ê³µë¶„ì‚° í–‰ë ¬ ê³„ì‚° (í‘œì¤€í™”ëœ ë°ì´í„°ì—ì„œëŠ” ìƒê´€ê´€ê³„ í–‰ë ¬ê³¼ ë™ì¼)
    const numVars = variableNames.length
    const covMatrix = Array(numVars).fill(null).map(() => Array(numVars).fill(0))
    
    for (let i = 0; i < numVars; i++) {
      for (let j = 0; j < numVars; j++) {
        let sum = 0
        for (let k = 0; k < standardizedData.length; k++) {
          sum += standardizedData[k][i] * standardizedData[k][j]
        }
        covMatrix[i][j] = sum / (standardizedData.length - 1)
      }
    }
    
    // ê³ ìœ ê°’ê³¼ ê³ ìœ ë²¡í„° ê³„ì‚° (ë°˜ë³µë²• ì‚¬ìš©)
    const eigenResults = computeTopEigenValues(covMatrix, Math.min(numVars, 6))
    
    // ì»´í¬ë„ŒíŠ¸ ìˆ˜ ê²°ì •
    const maxComponents = Math.min(variableNames.length, cleanData.length - 1)
    const finalNComponents = nComponents ? Math.min(nComponents, maxComponents) : Math.min(maxComponents, 2)
    
    // ìƒìœ„ ê³ ìœ ê°’/ê³ ìœ ë²¡í„° ì„ íƒ
    const selectedEigenvalues = eigenResults.eigenvalues.slice(0, finalNComponents)
    const selectedEigenvectors = eigenResults.eigenvectors.slice(0, finalNComponents)
    
    // ì„¤ëª… ë¶„ì‚° ê³„ì‚°
    const totalVariance = eigenResults.eigenvalues.reduce((sum: number, val: number) => sum + val, 0)
    const explainedVariance = selectedEigenvalues.map((val: number) => (val / totalVariance) * 100)
    const eigenvalues = selectedEigenvalues
    
    // ëˆ„ì  ì„¤ëª… ë¶„ì‚° ê³„ì‚°
    const cumulativeVariance = explainedVariance.reduce((acc: number[], val: number, index: number) => {
      acc.push((acc[index - 1] || 0) + val)
      return acc
    }, [] as number[])
    
    // PC ì ìˆ˜ ê³„ì‚° (í‘œì¤€í™”ëœ ë°ì´í„° Ã— ê³ ìœ ë²¡í„°)
    const scores = standardizedData.map(row => 
      selectedEigenvectors.map((eigenvector: number[]) => 
        row.reduce((sum, val, idx) => sum + val * eigenvector[idx], 0)
      )
    )
    
    // ë¡œë”© ê³„ì‚° (ê³ ìœ ë²¡í„° ìì²´ê°€ ë¡œë”©)
    const loadings = selectedEigenvectors
    
    // K-means í´ëŸ¬ìŠ¤í„°ë§ ìˆ˜í–‰ (ìœ íš¨í•œ ë°ì´í„°ë§Œ ì‚¬ìš©)
    const k = findOptimalClusters(scores.map(row => row.slice(0, 2))) // ì²« ë‘ ì»´í¬ë„ŒíŠ¸ë§Œ ì‚¬ìš©
    const clusters = kMeansClustering(scores, k)
    
    // ì›ë³¸ ë°ì´í„° í¬ê¸°ì— ë§ì¶° í´ëŸ¬ìŠ¤í„° ì •ë³´ í™•ì¥ (ìœ íš¨í•˜ì§€ ì•Šì€ í–‰ì€ -1ë¡œ í‘œì‹œ)
    const fullClusters = new Array(data.length).fill(-1)
    let validIndex = 0
    data.forEach((_, rowIndex) => {
      if (!invalidRows.includes(rowIndex)) {
        fullClusters[rowIndex] = clusters[validIndex] || 0
        validIndex++
      }
    })

    return {
      scores: scores,
      loadings: loadings,
      explainedVariance: explainedVariance,
      cumulativeVariance: cumulativeVariance,
      eigenvalues: eigenvalues,
      variableNames: variableNames,
      nComponents: finalNComponents,
      clusters: fullClusters  // ì „ì²´ í¬ê¸° ë°°ì—´ ë°˜í™˜
    }
    
  } catch (error) {
    console.error('PCA calculation error:', error)
    throw new Error(`PCA ê³„ì‚° ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: ${error instanceof Error ? error.message : 'Unknown error'}`)
  }
}

// ìƒìœ„ ê³ ìœ ê°’ê³¼ ê³ ìœ ë²¡í„° ê³„ì‚° í•¨ìˆ˜
function computeTopEigenValues(matrix: number[][], numComponents: number): { eigenvalues: number[], eigenvectors: number[][] } {
  const n = matrix.length
  const eigenvalues: number[] = []
  const eigenvectors: number[][] = []
  
  // ì‘ì—… í–‰ë ¬ ë³µì‚¬
  let workMatrix = matrix.map(row => [...row])
  
  for (let comp = 0; comp < numComponents; comp++) {
    // ì „ë ¥ë²•ìœ¼ë¡œ ê°€ì¥ í° ê³ ìœ ê°’ê³¼ ê³ ìœ ë²¡í„° ì°¾ê¸°
    let eigenvector = new Array(n).fill(0).map(() => Math.random() - 0.5) // ëœë¤ ì´ˆê¸° ë²¡í„°
    let eigenvalue = 0
    
    // ì „ë ¥ë²• ë°˜ë³µ
    for (let iter = 0; iter < 100; iter++) {
      // A * v
      const newVector = new Array(n).fill(0)
      for (let i = 0; i < n; i++) {
        for (let j = 0; j < n; j++) {
          newVector[i] += workMatrix[i][j] * eigenvector[j]
        }
      }
      
      // í¬ê¸° ê³„ì‚°
      const norm = Math.sqrt(newVector.reduce((sum, val) => sum + val * val, 0))
      if (norm < 1e-10) break
      
      // ì •ê·œí™”
      eigenvector = newVector.map(val => val / norm)
      
      // ê³ ìœ ê°’ ê³„ì‚° (Rayleigh quotient)
      let numerator = 0
      let denominator = 0
      for (let i = 0; i < n; i++) {
        let temp = 0
        for (let j = 0; j < n; j++) {
          temp += workMatrix[i][j] * eigenvector[j]
        }
        numerator += eigenvector[i] * temp
        denominator += eigenvector[i] * eigenvector[i]
      }
      
      const newEigenvalue = numerator / denominator
      
      // ìˆ˜ë ´ ì²´í¬
      if (Math.abs(newEigenvalue - eigenvalue) < 1e-8) break
      eigenvalue = newEigenvalue
    }
    
    // ê³ ìœ ê°’ì´ ì¶©ë¶„íˆ í° ê²½ìš°ë§Œ ì €ì¥
    if (Math.abs(eigenvalue) > 1e-10) {
      eigenvalues.push(Math.abs(eigenvalue))
      eigenvectors.push([...eigenvector])
      
      // ì°¾ì€ ê³ ìœ ë²¡í„°ì˜ ì˜í–¥ì„ ì œê±° (ë””í”Œë ˆì´ì…˜)
      for (let i = 0; i < n; i++) {
        for (let j = 0; j < n; j++) {
          workMatrix[i][j] -= eigenvalue * eigenvector[i] * eigenvector[j]
        }
      }
    }
  }
  
  // ê³ ìœ ê°’ í¬ê¸°ìˆœìœ¼ë¡œ ì •ë ¬
  const sortedIndices = eigenvalues
    .map((val, idx) => ({ val, idx }))
    .sort((a, b) => b.val - a.val)
    .map(item => item.idx)
  
  const sortedEigenvalues = sortedIndices.map(idx => eigenvalues[idx])
  const sortedEigenvectors = sortedIndices.map(idx => eigenvectors[idx])
  
  return {
    eigenvalues: sortedEigenvalues,
    eigenvectors: sortedEigenvectors
  }
} 

// K-means í´ëŸ¬ìŠ¤í„°ë§ í•¨ìˆ˜
function kMeansClustering(data: number[][], k: number, maxIterations: number = 100): number[] {
  if (data.length === 0 || k <= 0) return []
  
  // ë°ì´í„°ê°€ kë³´ë‹¤ ì ìœ¼ë©´ ê°ê°ì„ ë‹¤ë¥¸ í´ëŸ¬ìŠ¤í„°ë¡œ í• ë‹¹
  if (data.length <= k) {
    return data.map((_, index) => index)
  }
  
  // ì´ˆê¸° ì¤‘ì‹¬ì  ì„¤ì • (k-means++ ë°©ì‹ìœ¼ë¡œ ê°œì„ )
  const centroids: number[][] = []
  
  // ì²« ë²ˆì§¸ ì¤‘ì‹¬ì ì€ ëœë¤í•˜ê²Œ ì„ íƒ
  const firstIndex = Math.floor(Math.random() * data.length)
  centroids.push([...data[firstIndex]])
  
  // ë‚˜ë¨¸ì§€ ì¤‘ì‹¬ì ë“¤ì€ ê¸°ì¡´ ì¤‘ì‹¬ì ë“¤ë¡œë¶€í„° ê°€ì¥ ë¨¼ ì ì„ ì„ íƒ
  for (let i = 1; i < k; i++) {
    let maxDistance = -1
    let bestPoint = [...data[0]]
    
    for (const point of data) {
      let minDistToCentroid = Infinity
      
      // ê° ê¸°ì¡´ ì¤‘ì‹¬ì ê¹Œì§€ì˜ ìµœì†Œ ê±°ë¦¬ ê³„ì‚°
      for (const centroid of centroids) {
        const distance = Math.sqrt(
          Math.pow(point[0] - centroid[0], 2) + 
          Math.pow(point[1] - centroid[1], 2)
        )
        minDistToCentroid = Math.min(minDistToCentroid, distance)
      }
      
      // ê°€ì¥ ë¨¼ ì ì„ ë‹¤ìŒ ì¤‘ì‹¬ì ìœ¼ë¡œ ì„ íƒ
      if (minDistToCentroid > maxDistance) {
        maxDistance = minDistToCentroid
        bestPoint = [...point]
      }
    }
    
    centroids.push(bestPoint)
  }
  
  let clusters: number[] = new Array(data.length).fill(0)
  
  for (let iter = 0; iter < maxIterations; iter++) {
    let changed = false
    
    // ê° ë°ì´í„° í¬ì¸íŠ¸ë¥¼ ê°€ì¥ ê°€ê¹Œìš´ ì¤‘ì‹¬ì ì— í• ë‹¹
    for (let i = 0; i < data.length; i++) {
      let minDistance = Infinity
      let bestCluster = 0
      
      for (let j = 0; j < k; j++) {
        const distance = Math.sqrt(
          Math.pow(data[i][0] - centroids[j][0], 2) + 
          Math.pow(data[i][1] - centroids[j][1], 2)
        )
        
        if (distance < minDistance) {
          minDistance = distance
          bestCluster = j
        }
      }
      
      if (clusters[i] !== bestCluster) {
        clusters[i] = bestCluster
        changed = true
      }
    }
    
    // ì¤‘ì‹¬ì  ì—…ë°ì´íŠ¸
    for (let j = 0; j < k; j++) {
      const clusterPoints = data.filter((_, index) => clusters[index] === j)
      if (clusterPoints.length > 0) {
        centroids[j][0] = clusterPoints.reduce((sum, point) => sum + point[0], 0) / clusterPoints.length
        centroids[j][1] = clusterPoints.reduce((sum, point) => sum + point[1], 0) / clusterPoints.length
      }
    }
    
    if (!changed) break
  }
  
  return clusters
}

// Silhouette ìŠ¤ì½”ì–´ ê³„ì‚° (ê°„ë‹¨í•œ êµ¬í˜„)
function calculateSilhouetteScore(data: number[][], clusters: number[]): number {
  const n = data.length
  const k = Math.max(...clusters) + 1
  let totalSilhouette = 0
  
  for (let i = 0; i < n; i++) {
    const clusterI = clusters[i]
    
    // a(i): ê°™ì€ í´ëŸ¬ìŠ¤í„° ë‚´ í‰ê·  ê±°ë¦¬
    const sameCluster = data.filter((_, idx) => clusters[idx] === clusterI && idx !== i)
    const aI = sameCluster.length > 0 ? 
      sameCluster.reduce((sum, point) => sum + euclideanDistance(data[i], point), 0) / sameCluster.length : 0
    
    // b(i): ê°€ì¥ ê°€ê¹Œìš´ ë‹¤ë¥¸ í´ëŸ¬ìŠ¤í„°ê¹Œì§€ì˜ í‰ê·  ê±°ë¦¬
    let minBI = Infinity
    for (let c = 0; c < k; c++) {
      if (c !== clusterI) {
        const otherCluster = data.filter((_, idx) => clusters[idx] === c)
        if (otherCluster.length > 0) {
          const avgDist = otherCluster.reduce((sum, point) => sum + euclideanDistance(data[i], point), 0) / otherCluster.length
          minBI = Math.min(minBI, avgDist)
        }
      }
    }
    
    const bI = minBI === Infinity ? 0 : minBI
    const silhouette = aI === 0 && bI === 0 ? 0 : (bI - aI) / Math.max(aI, bI)
    totalSilhouette += silhouette
  }
  
  return totalSilhouette / n
}

// ìœ í´ë¦¬ë“œ ê±°ë¦¬ ê³„ì‚°
function euclideanDistance(point1: number[], point2: number[]): number {
  return Math.sqrt(point1.reduce((sum, val, idx) => sum + Math.pow(val - point2[idx], 2), 0))
}

// ê°œì„ ëœ ìµœì  í´ëŸ¬ìŠ¤í„° ìˆ˜ ê²°ì • (Silhouette + Elbow ë°©ë²•)
function findOptimalClusters(data: number[][], maxK: number = 8): number {
  if (data.length < 6) return 3 // ê¸°ë³¸ê°’ì„ 3ìœ¼ë¡œ ë³€ê²½
  
  // ë°ì´í„° í¬ê¸°ì— ë”°ë¥¸ ìµœëŒ€ í´ëŸ¬ìŠ¤í„° ìˆ˜ ê²°ì • (ì œí•œ ì™„í™”)
  const actualMaxK = Math.min(maxK, Math.floor(data.length / 2), 6) // ìµœëŒ€ 6ê°œ

  const wcss: number[] = []
  const silhouetteScores: number[] = []

  for (let k = 2; k <= actualMaxK; k++) {
    const clusters = kMeansClustering(data, k)
    
    // WCSS ê³„ì‚°
    let totalWCSS = 0
    for (let cluster = 0; cluster < k; cluster++) {
      const clusterPoints = data.filter((_, index) => clusters[index] === cluster)
      if (clusterPoints.length === 0) continue
      
      const centroid = clusterPoints[0].map((_, dim) => 
        clusterPoints.reduce((sum, point) => sum + point[dim], 0) / clusterPoints.length
      )
      
      const clusterWCSS = clusterPoints.reduce((sum, point) => {
        return sum + point.reduce((distSum, val, dim) => distSum + Math.pow(val - centroid[dim], 2), 0)
      }, 0)
      
      totalWCSS += clusterWCSS
    }
    wcss.push(totalWCSS)
    
    // Silhouette ìŠ¤ì½”ì–´ ê³„ì‚°
    const silScore = calculateSilhouetteScore(data, clusters)
    silhouetteScores.push(silScore)
  }
  
  // ìµœì  k ê²°ì •: Silhouette ìŠ¤ì½”ì–´ ìš°ì„ , ê·¸ ë‹¤ìŒ Elbow
  let bestK = 3 // ê¸°ë³¸ê°’ì„ 3ìœ¼ë¡œ ì„¤ì •
  let maxSilhouette = -1
  
  // Silhouette ìŠ¤ì½”ì–´ ê¸°ë°˜ ìµœì í™”
  for (let i = 0; i < silhouetteScores.length; i++) {
    const k = i + 2
    const silScore = silhouetteScores[i]
    
    // Silhouette ìŠ¤ì½”ì–´ê°€ ì¢‹ê³ , 3ê°œ ì´ìƒì˜ í´ëŸ¬ìŠ¤í„°ë¥¼ ì„ í˜¸
    if (silScore > maxSilhouette && silScore >= 0.15) { // ê¸°ì¤€ ì™„í™”
      maxSilhouette = silScore
      bestK = k
    }
  }
  
  // 3ê°œ í´ëŸ¬ìŠ¤í„° ì„ í˜¸í•˜ëŠ” ë¡œì§ ì¶”ê°€
  if (silhouetteScores.length >= 2) { // k=3ì´ ê°€ëŠ¥í•œ ê²½ìš°
    const k3Score = silhouetteScores[1] // k=3ì˜ ìŠ¤ì½”ì–´
    const k2Score = silhouetteScores[0] // k=2ì˜ ìŠ¤ì½”ì–´

    // k=3ì´ k=2ë³´ë‹¤ ì¡°ê¸ˆì´ë¼ë„ ì¢‹ê±°ë‚˜, ê±°ì˜ ë¹„ìŠ·í•˜ë©´ k=3 ì„ íƒ
    if (k3Score >= k2Score - 0.05) { // 0.05 ì°¨ì´ê¹Œì§€ëŠ” k=3 ì„ í˜¸
      bestK = 3
      maxSilhouette = k3Score
    }
  }

  return Math.max(2, Math.min(bestK, actualMaxK))
}

// PCA ê³„ì‚° í•¨ìˆ˜ (sklearn.decomposition.PCAì™€ ë™ì¼í•œ ë°©ì‹)
export async function calculatePCA(
  data: number[][],
  variableNames: string[],
  nComponents?: number
): Promise<PCAResult> {
  try {
    if (!data || data.length === 0) {
      throw new Error('PCAë¥¼ ìœ„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.')
    }

    // ë°ì´í„° ê²€ì¦ ë° ì •ë¦¬
    const cleanData = data.filter(row => 
      row.every(val => !isNaN(val) && isFinite(val))
    )

    if (cleanData.length < 3) {
      throw new Error('PCA ê³„ì‚°ì„ ìœ„í•´ ìµœì†Œ 3ê°œì˜ ìœ íš¨í•œ ìƒ˜í”Œì´ í•„ìš”í•©ë‹ˆë‹¤.')
    }

    const numVars = variableNames.length
    const numSamples = cleanData.length

    if (numSamples <= numVars) {
      throw new Error('ìƒ˜í”Œ ìˆ˜ê°€ ë³€ìˆ˜ ìˆ˜ë³´ë‹¤ ë§ì•„ì•¼ í•©ë‹ˆë‹¤.')
    }

    console.log('ğŸ” PCA ì‹œì‘:', {
      samples: numSamples,
      variables: numVars,
      variableNames
    })

    // 1. ë°ì´í„° í‘œì¤€í™” (sklearn StandardScalerì™€ ë™ì¼í•œ ë°©ì‹)
    const means = new Array(numVars).fill(0)
    const stds = new Array(numVars).fill(0)
    
    // í‰ê·  ê³„ì‚°
    for (let j = 0; j < numVars; j++) {
      means[j] = cleanData.reduce((sum, row) => sum + row[j], 0) / numSamples
    }
    
    // í‘œì¤€í¸ì°¨ ê³„ì‚° (Bessel's correction: n-1)
    for (let j = 0; j < numVars; j++) {
      const variance = cleanData.reduce((sum, row) => sum + Math.pow(row[j] - means[j], 2), 0) / (numSamples - 1)
      stds[j] = Math.sqrt(variance)
    }
    
    // í‘œì¤€í™”ëœ ë°ì´í„° ìƒì„±
    const standardizedData = cleanData.map(row =>
      row.map((val, j) => stds[j] > 0 ? (val - means[j]) / stds[j] : 0)
    )

    // 2. ML-Matrixë¥¼ ì‚¬ìš©í•œ ê³µë¶„ì‚° í–‰ë ¬ ê³„ì‚°
    const dataMatrix = new Matrix(standardizedData)
    
    // ê³µë¶„ì‚° í–‰ë ¬ = (X^T * X) / (n-1)
    const covMatrix = dataMatrix.transpose().mmul(dataMatrix).div(numSamples - 1)

    // 3. ê³ ìœ ê°’ ë¶„í•´ (EVD) ì‚¬ìš©
    const evd = new (EVD as any)(covMatrix)
    const eigenvaluesRaw = (evd as any).realEigenvalues as number[]
    const eigenvalues = [...eigenvaluesRaw].reverse() // ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
    const eigenvectorsRaw = (evd as any).eigenvectorMatrix.transpose().to2DArray() as number[][]
    const eigenvectors = [...eigenvectorsRaw].reverse() // ê³ ìœ ë²¡í„°ë“¤

    // ì»´í¬ë„ŒíŠ¸ ìˆ˜ ê²°ì •
    const maxComponents = Math.min(variableNames.length, cleanData.length - 1)
    const finalNComponents = nComponents ? Math.min(nComponents, maxComponents) : Math.min(maxComponents, 2)
    
    // ìƒìœ„ ê³ ìœ ê°’/ê³ ìœ ë²¡í„° ì„ íƒ
    const selectedEigenvalues = eigenvalues.slice(0, finalNComponents)
    const selectedEigenvectors = eigenvectors.slice(0, finalNComponents)
    
    // 4. ì„¤ëª… ë¶„ì‚° ê³„ì‚° (sklearnê³¼ ë™ì¼í•œ ë°©ì‹)
    const totalVariance = eigenvalues.reduce((sum: number, val: number) => sum + Math.max(0, val), 0) // ìŒìˆ˜ ê³ ìœ ê°’ ì œê±°
    const explainedVariance = selectedEigenvalues.map((val: number) => (Math.max(0, val) / totalVariance) * 100)
    
    // ëˆ„ì  ì„¤ëª… ë¶„ì‚° ê³„ì‚°
    const cumulativeVariance = explainedVariance.reduce((acc: number[], val: number, index: number) => {
      acc.push((acc[index - 1] || 0) + val)
      return acc
    }, [])

    // 5. PC ì ìˆ˜ ê³„ì‚° (í‘œì¤€í™”ëœ ë°ì´í„° Ã— ê³ ìœ ë²¡í„°)
    const scores = standardizedData.map(sample => 
      selectedEigenvectors.map((eigenvector: number[]) => 
        sample.reduce((sum, val, i) => sum + val * eigenvector[i], 0)
      )
    )

    // 6. ë¡œë”© í–‰ë ¬ ê³„ì‚° (ê³ ìœ ë²¡í„° Ã— sqrt(ê³ ìœ ê°’))
    const loadings = selectedEigenvectors.map((eigenvector: number[], compIndex: number) =>
      eigenvector.map((loading: number) => loading * Math.sqrt(Math.max(0, selectedEigenvalues[compIndex])))
    )

    return {
      scores,
      loadings,
      explainedVariance,
      cumulativeVariance,
      eigenvalues: selectedEigenvalues,
      variableNames,
      nComponents: finalNComponents,
      clusters: [] // í´ëŸ¬ìŠ¤í„°ë§ì€ ë³„ë„ë¡œ ìˆ˜í–‰
    }

  } catch (error) {
    console.error('PCA calculation error:', error)
    throw new Error(`PCA ê³„ì‚° ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: ${error instanceof Error ? error.message : 'Unknown error'}`)
  }
} 