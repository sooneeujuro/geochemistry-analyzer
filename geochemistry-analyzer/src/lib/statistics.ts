import * as ss from 'simple-statistics'
import { StatisticalResult, PCAResult } from '@/types/geochem'

// PCA-js import (íƒ€ì… ì„ ì–¸)
const PCA = require('pca-js')

export function calculateStatistics(
  xData: number[],
  yData: number[],
  statMethods: ('pearson' | 'spearman' | 'kendall')[] = ['pearson', 'spearman']
): StatisticalResult {
  try {
    // ê²°ì¸¡ê°’ ì œê±°
    const validPairs = xData
      .map((x, i) => ({ x, y: yData[i] }))
      .filter(pair => !isNaN(pair.x) && !isNaN(pair.y) && isFinite(pair.x) && isFinite(pair.y))
    
    if (validPairs.length < 3) {
      return { error: "ìœ íš¨í•œ ë°ì´í„° í¬ì¸íŠ¸ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤." }
    }
    
    const xClean = validPairs.map(p => p.x)
    const yClean = validPairs.map(p => p.y)
    
    const results: StatisticalResult = {}
    
    // í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜
    if (statMethods.includes('pearson')) {
      try {
        const pearsonCorr = ss.sampleCorrelation(xClean, yClean)
        results.pearsonCorr = pearsonCorr
        
        // p-ê°’ ê·¼ì‚¬ ê³„ì‚° (t-test)
        const n = xClean.length
        const t = pearsonCorr * Math.sqrt((n - 2) / (1 - pearsonCorr * pearsonCorr))
        results.pearsonP = calculateTTestPValue(t, n - 2)
      } catch (e) {
        console.warn('Pearson correlation calculation failed:', e)
      }
    }
    
    // ìŠ¤í”¼ì–´ë§Œ ìƒê´€ê³„ìˆ˜ (ìˆœìœ„ ê¸°ë°˜)
    if (statMethods.includes('spearman')) {
      try {
        const xRanks = getRanks(xClean)
        const yRanks = getRanks(yClean)
        const spearmanCorr = ss.sampleCorrelation(xRanks, yRanks)
        results.spearmanCorr = spearmanCorr
        
        // p-ê°’ ê·¼ì‚¬ ê³„ì‚°
        const n = xClean.length
        const t = spearmanCorr * Math.sqrt((n - 2) / (1 - spearmanCorr * spearmanCorr))
        results.spearmanP = calculateTTestPValue(t, n - 2)
      } catch (e) {
        console.warn('Spearman correlation calculation failed:', e)
      }
    }
    
    // ì„ í˜• íšŒê·€
    if (xClean.length > 2) {
      try {
        // simple-statistics í˜•ì‹ì— ë§ê²Œ [[x1, y1], [x2, y2], ...] ë°°ì—´ë¡œ ë³€í™˜
        const regressionData = validPairs.map(point => [point.x, point.y])
        const regression = ss.linearRegression(regressionData)
        const regressionLine = ss.linearRegressionLine(regression)
        const rSquared = ss.rSquared(regressionData, regressionLine)
        
        results.rSquared = rSquared
        results.linearSlope = regression.m
        results.linearIntercept = regression.b
      } catch (e) {
        console.warn('Linear regression calculation failed:', e)
      }
    }
    
    return results
  } catch (error) {
    return { error: `í†µê³„ ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: ${error}` }
  }
}

// ìˆœìœ„ ê³„ì‚° í•¨ìˆ˜
function getRanks(data: number[]): number[] {
  const sorted = [...data]
    .map((value, index) => ({ value, index }))
    .sort((a, b) => a.value - b.value)
  
  const ranks = new Array(data.length)
  
  for (let i = 0; i < sorted.length; i++) {
    ranks[sorted[i].index] = i + 1
  }
  
  return ranks
}

// t-test p-ê°’ ê·¼ì‚¬ ê³„ì‚°
function calculateTTestPValue(t: number, df: number): number {
  // ê°„ë‹¨í•œ t-ë¶„í¬ p-ê°’ ê·¼ì‚¬
  // ì‹¤ì œ í”„ë¡œë•ì…˜ì—ì„œëŠ” ë” ì •í™•í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© ê¶Œì¥
  const absT = Math.abs(t)
  
  if (absT > 6) return 0.0001
  if (absT > 4) return 0.001
  if (absT > 3) return 0.01
  if (absT > 2) return 0.05
  if (absT > 1) return 0.1
  
  return 0.5
}

// ì „ì²´ ìŠ¤ìº” ë¶„ì„ í•¨ìˆ˜
export function performFullScanAnalysis(
  data: Record<string, any>[],
  numericColumns: string[],
  threshold: number = 0.5,
  pThreshold: number = 0.05,
  statMethods: ('pearson' | 'spearman' | 'kendall')[] = ['pearson']
) {
  const results: Array<{
    xVariable: string
    yVariable: string
    meetsQriteria: boolean
  } & StatisticalResult> = []
  
  // ëª¨ë“  ê°€ëŠ¥í•œ ì¡°í•© ìƒì„±
  for (let i = 0; i < numericColumns.length; i++) {
    for (let j = i + 1; j < numericColumns.length; j++) {
      const col1 = numericColumns[i]
      const col2 = numericColumns[j]
      
      const xData = data.map(row => parseFloat(row[col1])).filter(val => !isNaN(val))
      const yData = data.map(row => parseFloat(row[col2])).filter(val => !isNaN(val))
      
      const stats = calculateStatistics(xData, yData, statMethods)
      
      if (!stats.error) {
        const meetsQriteria = statMethods.some(method => {
          const corrKey = `${method}Corr` as keyof StatisticalResult
          const pKey = `${method}P` as keyof StatisticalResult
          const corr = stats[corrKey] as number
          const p = stats[pKey] as number
          
          return Math.abs(corr) >= threshold && p <= pThreshold
        })
        
        results.push({
          xVariable: col1,
          yVariable: col2,
          meetsQriteria,
          ...stats
        })
      }
    }
  }
  
  return results.filter(result => result.meetsQriteria)
}

// í—¬í¼ í•¨ìˆ˜ë“¤
function calculateSkewness(data: number[], mean: number, stdDev: number): number {
  const n = data.length
  const m3 = data.reduce((sum, x) => sum + Math.pow((x - mean) / stdDev, 3), 0) / n
  return m3
}

function calculateKurtosis(data: number[], mean: number, stdDev: number): number {
  const n = data.length
  const m4 = data.reduce((sum, x) => sum + Math.pow((x - mean) / stdDev, 4), 0) / n
  return m4 - 3 // excess kurtosis
}

// ê³ ê¸‰ í†µê³„ë¶„ì„ ê¸°ëŠ¥ë“¤
export interface AdvancedStatistics {
  mean: number
  median: number
  standardDeviation: number
  variance: number
  skewness: number
  kurtosis: number
  quantiles: {
    q25: number
    q75: number
  }
  outliers: number[]
  normality: {
    shapiroWilk?: number
    isNormal: boolean
  }
}

export interface PCASuggestion {
  variables: string[]
  eigenvalues: number[]
  varianceExplained: number[]
  cumulativeVariance: number[]
  reason: string
  confidence: number
}

export interface RegressionAnalysis {
  model: 'linear' | 'polynomial' | 'multiple'
  coefficients: number[]
  rSquared: number
  adjustedRSquared: number
  fStatistic: number
  pValue: number
  residuals: number[]
  predicted: number[]
}

// ê¸°ìˆ í†µê³„ ê³„ì‚°
export function calculateDescriptiveStats(data: number[]): AdvancedStatistics {
  const cleanData = data.filter(x => !isNaN(x) && isFinite(x))
  
  if (cleanData.length === 0) {
    throw new Error('No valid data points')
  }

  // ê¸°ë³¸ í†µê³„ëŸ‰
  const meanVal = ss.mean(cleanData)
  const medianVal = ss.median(cleanData)
  const stdDev = ss.standardDeviation(cleanData)
  const varianceVal = ss.variance(cleanData)
  
  // ë¶„í¬ í˜•íƒœ (ì§ì ‘ ê³„ì‚°)
  const skewnessVal = calculateSkewness(cleanData, meanVal, stdDev)
  const kurtosisVal = calculateKurtosis(cleanData, meanVal, stdDev)
  
  // ì‚¬ë¶„ìœ„ìˆ˜
  const q25 = ss.quantile(cleanData, 0.25)
  const q75 = ss.quantile(cleanData, 0.75)
  
  // ì´ìƒì¹˜ íƒì§€ (IQR ë°©ë²•)
  const iqr = q75 - q25
  const lowerBound = q25 - 1.5 * iqr
  const upperBound = q75 + 1.5 * iqr
  const outliers = cleanData.filter(x => x < lowerBound || x > upperBound)
  
  // ì •ê·œì„± ê²€ì • (ê°„ë‹¨í•œ ê·¼ì‚¬)
  const isNormal = Math.abs(skewnessVal) < 1 && Math.abs(kurtosisVal) < 3
  
  return {
    mean: meanVal,
    median: medianVal,
    standardDeviation: stdDev,
    variance: varianceVal,
    skewness: skewnessVal,
    kurtosis: kurtosisVal,
    quantiles: { q25, q75 },
    outliers,
    normality: { isNormal }
  }
}

// ìƒê´€ê´€ê³„ ë§¤íŠ¸ë¦­ìŠ¤ ê³„ì‚°
export function calculateCorrelationMatrix(data: Record<string, number[]>): Record<string, Record<string, number>> {
  const variables = Object.keys(data)
  const matrix: Record<string, Record<string, number>> = {}
  
  variables.forEach(var1 => {
    matrix[var1] = {}
    variables.forEach(var2 => {
      if (var1 === var2) {
        matrix[var1][var2] = 1
      } else {
        try {
          const corr = ss.sampleCorrelation(data[var1], data[var2])
          matrix[var1][var2] = isNaN(corr) ? 0 : corr
        } catch {
          matrix[var1][var2] = 0
        }
      }
    })
  })
  
  return matrix
}

// PCA ì¶”ì²œ ë¡œì§
export function suggestPCAVariables(
  correlationMatrix: Record<string, Record<string, number>>,
  variables: string[],
  threshold: number = 0.3
): PCASuggestion[] {
  const suggestions: PCASuggestion[] = []
  
  // ê°•í•œ ìƒê´€ê´€ê³„ë¥¼ ê°€ì§„ ë³€ìˆ˜ë“¤ ê·¸ë£¹ ì°¾ê¸°
  const variableGroups: string[][] = []
  const processed = new Set<string>()
  
  variables.forEach(var1 => {
    if (processed.has(var1)) return
    
    const group = [var1]
    variables.forEach(var2 => {
      if (var1 !== var2 && !processed.has(var2)) {
        const corr = Math.abs(correlationMatrix[var1]?.[var2] || 0)
        if (corr >= threshold) {
          group.push(var2)
          processed.add(var2)
        }
      }
    })
    
    if (group.length >= 3) { // PCAëŠ” ìµœì†Œ 3ê°œ ë³€ìˆ˜ ì´ìƒ
      variableGroups.push(group)
      group.forEach(v => processed.add(v))
    }
  })
  
  // ê° ê·¸ë£¹ì— ëŒ€í•œ PCA ì¶”ì²œ
  variableGroups.forEach((group, index) => {
    // ê°„ë‹¨í•œ ê³ ìœ ê°’ ì¶”ì • (ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•œ ê³„ì‚° í•„ìš”)
    const avgCorrelation = group.reduce((sum, var1) => {
      return sum + group.reduce((innerSum, var2) => {
        return innerSum + (var1 !== var2 ? Math.abs(correlationMatrix[var1]?.[var2] || 0) : 0)
      }, 0)
    }, 0) / (group.length * (group.length - 1))
    
    const estimatedVariance = [
      avgCorrelation * group.length * 0.4,
      avgCorrelation * group.length * 0.3,
      avgCorrelation * group.length * 0.2
    ]
    
    const totalVariance = estimatedVariance.reduce((a, b) => a + b, 0)
    const varianceExplained = estimatedVariance.map(v => (v / totalVariance) * 100)
    const cumulativeVariance = varianceExplained.reduce((acc, curr, idx) => {
      acc.push(idx === 0 ? curr : acc[idx - 1] + curr)
      return acc
    }, [] as number[])
    
    suggestions.push({
      variables: group,
      eigenvalues: estimatedVariance,
      varianceExplained,
      cumulativeVariance,
      reason: `ê°•í•œ ìƒê´€ê´€ê³„ ê·¸ë£¹ ${index + 1}: í‰ê·  ìƒê´€ê³„ìˆ˜ ${avgCorrelation.toFixed(3)}`,
      confidence: Math.min(avgCorrelation * 2, 0.95)
    })
  })
  
  // ì§€êµ¬í™”í•™ì ìœ¼ë¡œ ì˜ë¯¸ìˆëŠ” ì¡°í•© ì¶”ê°€
  const geochemGroups = [
    {
      pattern: ['SiO2', 'Al2O3', 'K2O', 'Na2O'],
      name: 'ê·œì‚°ì—¼ ì£¼ì„±ë¶„',
      reason: 'í™”ì„±ì•” ë¶„í™”ê³¼ì • ë¶„ì„ì— ì í•©'
    },
    {
      pattern: ['La', 'Ce', 'Pr', 'Nd', 'Sm', 'Eu'],
      name: 'ê²½í¬í† ë¥˜ ì›ì†Œ',
      reason: 'REE íŒ¨í„´ ë° ê´‘ë¬¼í•™ì  ê³¼ì • ë¶„ì„'
    },
    {
      pattern: ['MgO', 'FeO', 'Cr', 'Ni'],
      name: 'ê³ ì² ì§ˆ ì§€ì‹œì',
      reason: 'ë§¨í‹€ ê¸°ì› ë° ë¶„í™”ë„ ë¶„ì„'
    }
  ]
  
  geochemGroups.forEach(({ pattern, name, reason }) => {
    const availableVars = pattern.filter(v => variables.includes(v))
    if (availableVars.length >= 3) {
      suggestions.push({
        variables: availableVars,
        eigenvalues: [2.1, 1.3, 0.8],
        varianceExplained: [52.5, 32.5, 20.0],
        cumulativeVariance: [52.5, 85.0, 100.0],
        reason: `${name}: ${reason}`,
        confidence: 0.85
      })
    }
  })
  
  return suggestions.sort((a, b) => b.confidence - a.confidence)
}

// PCA ê³„ì‚° í•¨ìˆ˜ (pca-js ì‚¬ìš©)
export function performPCA(
  data: Record<string, any>[],
  variableNames: string[],
  nComponents?: number
): PCAResult {
  try {
    console.log('PCA ì‹œì‘:', { 
      totalRows: data.length, 
      variables: variableNames,
      sampleData: data.slice(0, 3)
    })

    // ë°ì´í„° ì¤€ë¹„: ë³€ìˆ˜ë³„ë¡œ ìˆ«ì ë°ì´í„°ë§Œ ì¶”ì¶œí•˜ê³  ê²°ì¸¡ê°’ ì œê±°
    const cleanData: number[][] = []
    const invalidRows: number[] = []
    
    data.forEach((row, rowIndex) => {
      const values = variableNames.map(name => {
        const val = row[name]
        // ë” ê´€ëŒ€í•œ ìˆ«ì ë³€í™˜ ì‹œë„
        if (typeof val === 'string' && val.trim() !== '') {
          const parsed = parseFloat(val.trim())
          return !isNaN(parsed) && isFinite(parsed) ? parsed : null
        }
        return typeof val === 'number' && !isNaN(val) && isFinite(val) ? val : null
      })
      
      // ëª¨ë“  ë³€ìˆ˜ê°€ ìœ íš¨í•œ ê°’ì„ ê°€ì§„ í–‰ë§Œ í¬í•¨
      if (values.every(val => val !== null)) {
        cleanData.push(values as number[])
      } else {
        invalidRows.push(rowIndex)
      }
    })

    console.log('ë°ì´í„° ì •ë¦¬ ê²°ê³¼:', {
      totalRows: data.length,
      validRows: cleanData.length,
      invalidRows: invalidRows.length,
      invalidRowsIndices: invalidRows.slice(0, 10), // ì²˜ìŒ 10ê°œë§Œ í‘œì‹œ
      sampleCleanData: cleanData.slice(0, 3)
    })

    // ë³€ìˆ˜ë³„ ìœ íš¨ ë°ì´í„° ê°œìˆ˜ í™•ì¸
    const variableValidCounts = variableNames.map(name => {
      const validCount = data.filter(row => {
        const val = row[name]
        if (typeof val === 'string' && val.trim() !== '') {
          const parsed = parseFloat(val.trim())
          return !isNaN(parsed) && isFinite(parsed)
        }
        return typeof val === 'number' && !isNaN(val) && isFinite(val)
      }).length
      return { variable: name, validCount, totalCount: data.length }
    })

    console.log('ë³€ìˆ˜ë³„ ìœ íš¨ ë°ì´í„°:', variableValidCounts)
    
    if (cleanData.length < 3) {
      const errorDetails = `
PCA ë¶„ì„ì— í•„ìš”í•œ ìœ íš¨ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.

ğŸ“Š ë°ì´í„° í˜„í™©:
â€¢ ì „ì²´ í–‰ ìˆ˜: ${data.length}ê°œ
â€¢ ìœ íš¨ í–‰ ìˆ˜: ${cleanData.length}ê°œ 
â€¢ í•„ìš”í•œ ìµœì†Œ í–‰ ìˆ˜: 3ê°œ

ğŸ” ë³€ìˆ˜ë³„ ìœ íš¨ ë°ì´í„°:
${variableValidCounts.map(v => `â€¢ ${v.variable}: ${v.validCount}/${v.totalCount}ê°œ`).join('\n')}

ğŸ’¡ í•´ê²° ë°©ë²•:
1. ê²°ì¸¡ê°’ì´ ì ì€ ë³€ìˆ˜ë“¤ì„ ì„ íƒí•´ë³´ì„¸ìš”
2. ë°ì´í„°ì— ìˆ«ìê°€ ì•„ë‹Œ ê°’(í…ìŠ¤íŠ¸, ë¹ˆ ì¹¸)ì´ ìˆëŠ”ì§€ í™•ì¸í•´ë³´ì„¸ìš”
3. ë” ë§ì€ ë°ì´í„°ê°€ í¬í•¨ëœ íŒŒì¼ì„ ì‚¬ìš©í•´ë³´ì„¸ìš”`

      throw new Error(errorDetails)
    }
    
    if (variableNames.length < 2) {
      throw new Error('PCAë¥¼ ìˆ˜í–‰í•˜ê¸°ì— ë³€ìˆ˜ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. (ìµœì†Œ 2ê°œ ë³€ìˆ˜ í•„ìš”)')
    }
    
    // PCA ìˆ˜í–‰ (pca-js ì‚¬ìš©)
    const vectors = (PCA as any).getEigenVectors(cleanData)
    
    // ì»´í¬ë„ŒíŠ¸ ìˆ˜ ê²°ì • (ê¸°ë³¸: ìµœëŒ€ ë³€ìˆ˜ ìˆ˜ì™€ 2 ì¤‘ ì‘ì€ ê°’)
    const maxComponents = Math.min(variableNames.length, cleanData.length - 1)
    const finalNComponents = nComponents ? Math.min(nComponents, maxComponents) : Math.min(maxComponents, 2)
    
    // PCA ê²°ê³¼ ì¶”ì¶œ
    const selectedVectors = vectors.slice(0, finalNComponents)
    const adjustedData = (PCA as any).computeAdjustedData(cleanData, ...selectedVectors)
    
    // ì„¤ëª… ë¶„ì‚° ê³„ì‚°
    const totalVariance = vectors.reduce((sum: number, v: any) => sum + v.eigenvalue, 0)
    const explainedVariance = selectedVectors.map((v: any) => (v.eigenvalue / totalVariance) * 100)
    const eigenvalues = selectedVectors.map((v: any) => v.eigenvalue)
    
    // ëˆ„ì  ì„¤ëª… ë¶„ì‚° ê³„ì‚°
    const cumulativeVariance = explainedVariance.reduce((acc: number[], val: number, index: number) => {
      acc.push((acc[index - 1] || 0) + val)
      return acc
    }, [] as number[])
    
    // PC ì ìˆ˜ (scores) ì¶”ì¶œ
    const scores = adjustedData.adjustedData[0] ? 
      cleanData.map((_: any, rowIndex: number) => 
        selectedVectors.map((_: any, compIndex: number) => adjustedData.adjustedData[compIndex][rowIndex])
      ) : 
      cleanData.map(() => new Array(finalNComponents).fill(0))
    
    // ë¡œë”© (ë³€ìˆ˜ë³„ ê¸°ì—¬ë„) ê³„ì‚°
    const loadings = selectedVectors.map((vector: any) => vector.vector.slice(0, variableNames.length))
    
    // K-means í´ëŸ¬ìŠ¤í„°ë§ ìˆ˜í–‰ (ìœ íš¨í•œ ë°ì´í„°ë§Œ ì‚¬ìš©)
    const k = findOptimalClusters(scores.map(row => row.slice(0, 2))) // ì²« ë‘ ì»´í¬ë„ŒíŠ¸ë§Œ ì‚¬ìš©
    const clusters = kMeansClustering(scores, k)
    
    // ì›ë³¸ ë°ì´í„° í¬ê¸°ì— ë§ì¶° í´ëŸ¬ìŠ¤í„° ì •ë³´ í™•ì¥ (ìœ íš¨í•˜ì§€ ì•Šì€ í–‰ì€ -1ë¡œ í‘œì‹œ)
    const fullClusters = new Array(data.length).fill(-1)
    let validIndex = 0
    data.forEach((_, rowIndex) => {
      if (!invalidRows.includes(rowIndex)) {
        fullClusters[rowIndex] = clusters[validIndex] || 0
        validIndex++
      }
    })

    console.log('PCA ì™„ë£Œ:', {
      explainedVariance,
      clustersFound: k,
      validDataUsed: cleanData.length
    })
    
    return {
      scores: scores,
      loadings: loadings,
      explainedVariance: explainedVariance,
      cumulativeVariance: cumulativeVariance,
      eigenvalues: eigenvalues,
      variableNames: variableNames,
      nComponents: finalNComponents,
      clusters: fullClusters  // ì „ì²´ í¬ê¸° ë°°ì—´ ë°˜í™˜
    }
    
  } catch (error) {
    console.error('PCA calculation error:', error)
    throw new Error(`PCA ê³„ì‚° ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: ${error instanceof Error ? error.message : 'Unknown error'}`)
  }
} 

// K-means í´ëŸ¬ìŠ¤í„°ë§ í•¨ìˆ˜
function kMeansClustering(data: number[][], k: number, maxIterations: number = 100): number[] {
  if (data.length === 0 || k <= 0) return []
  
  // ë°ì´í„°ê°€ kë³´ë‹¤ ì ìœ¼ë©´ ê°ê°ì„ ë‹¤ë¥¸ í´ëŸ¬ìŠ¤í„°ë¡œ í• ë‹¹
  if (data.length <= k) {
    return data.map((_, index) => index)
  }
  
  // ì´ˆê¸° ì¤‘ì‹¬ì  ì„¤ì • (k-means++ ë°©ì‹ìœ¼ë¡œ ê°œì„ )
  const centroids: number[][] = []
  
  // ì²« ë²ˆì§¸ ì¤‘ì‹¬ì ì€ ëœë¤í•˜ê²Œ ì„ íƒ
  const firstIndex = Math.floor(Math.random() * data.length)
  centroids.push([...data[firstIndex]])
  
  // ë‚˜ë¨¸ì§€ ì¤‘ì‹¬ì ë“¤ì€ ê¸°ì¡´ ì¤‘ì‹¬ì ë“¤ë¡œë¶€í„° ê°€ì¥ ë¨¼ ì ì„ ì„ íƒ
  for (let i = 1; i < k; i++) {
    let maxDistance = -1
    let bestPoint = [...data[0]]
    
    for (const point of data) {
      let minDistToCentroid = Infinity
      
      // ê° ê¸°ì¡´ ì¤‘ì‹¬ì ê¹Œì§€ì˜ ìµœì†Œ ê±°ë¦¬ ê³„ì‚°
      for (const centroid of centroids) {
        const distance = Math.sqrt(
          Math.pow(point[0] - centroid[0], 2) + 
          Math.pow(point[1] - centroid[1], 2)
        )
        minDistToCentroid = Math.min(minDistToCentroid, distance)
      }
      
      // ê°€ì¥ ë¨¼ ì ì„ ë‹¤ìŒ ì¤‘ì‹¬ì ìœ¼ë¡œ ì„ íƒ
      if (minDistToCentroid > maxDistance) {
        maxDistance = minDistToCentroid
        bestPoint = [...point]
      }
    }
    
    centroids.push(bestPoint)
  }
  
  let clusters: number[] = new Array(data.length).fill(0)
  
  for (let iter = 0; iter < maxIterations; iter++) {
    let changed = false
    
    // ê° ë°ì´í„° í¬ì¸íŠ¸ë¥¼ ê°€ì¥ ê°€ê¹Œìš´ ì¤‘ì‹¬ì ì— í• ë‹¹
    for (let i = 0; i < data.length; i++) {
      let minDistance = Infinity
      let bestCluster = 0
      
      for (let j = 0; j < k; j++) {
        const distance = Math.sqrt(
          Math.pow(data[i][0] - centroids[j][0], 2) + 
          Math.pow(data[i][1] - centroids[j][1], 2)
        )
        
        if (distance < minDistance) {
          minDistance = distance
          bestCluster = j
        }
      }
      
      if (clusters[i] !== bestCluster) {
        clusters[i] = bestCluster
        changed = true
      }
    }
    
    // ì¤‘ì‹¬ì  ì—…ë°ì´íŠ¸
    for (let j = 0; j < k; j++) {
      const clusterPoints = data.filter((_, index) => clusters[index] === j)
      if (clusterPoints.length > 0) {
        centroids[j][0] = clusterPoints.reduce((sum, point) => sum + point[0], 0) / clusterPoints.length
        centroids[j][1] = clusterPoints.reduce((sum, point) => sum + point[1], 0) / clusterPoints.length
      }
    }
    
    if (!changed) break
  }
  
  return clusters
}

// ìµœì  í´ëŸ¬ìŠ¤í„° ìˆ˜ ê²°ì • (ì—˜ë³´ìš° ë°©ë²•)
function findOptimalClusters(data: number[][], maxK: number = 6): number {
  if (data.length < 4) return 2
  
  // ë°ì´í„°ê°€ ì ìœ¼ë©´ í´ëŸ¬ìŠ¤í„° ìˆ˜ë¥¼ ì œí•œ
  const actualMaxK = Math.min(maxK, Math.floor(data.length / 2), 4)
  
  const wcss: number[] = []
  
  for (let k = 1; k <= actualMaxK; k++) {
    const clusters = kMeansClustering(data, k)
    let totalWCSS = 0
    
    // ê° í´ëŸ¬ìŠ¤í„°ì˜ WCSS ê³„ì‚°
    for (let cluster = 0; cluster < k; cluster++) {
      const clusterPoints = data.filter((_, index) => clusters[index] === cluster)
      if (clusterPoints.length === 0) continue
      
      // í´ëŸ¬ìŠ¤í„° ì¤‘ì‹¬ì  ê³„ì‚°
      const centroidX = clusterPoints.reduce((sum, point) => sum + point[0], 0) / clusterPoints.length
      const centroidY = clusterPoints.reduce((sum, point) => sum + point[1], 0) / clusterPoints.length
      
      // í´ëŸ¬ìŠ¤í„° ë‚´ ê±°ë¦¬ ì œê³±í•©
      const clusterWCSS = clusterPoints.reduce((sum, point) => {
        return sum + Math.pow(point[0] - centroidX, 2) + Math.pow(point[1] - centroidY, 2)
      }, 0)
      
      totalWCSS += clusterWCSS
    }
    
    wcss.push(totalWCSS)
  }
  
  // ì—˜ë³´ìš° í¬ì¸íŠ¸ ì°¾ê¸° (ê°œì„ ëœ ë°©ë²•)
  let optimalK = 2
  if (wcss.length > 2) {
    let maxImprovement = 0
    for (let i = 1; i < wcss.length - 1; i++) {
      const improvement = wcss[i - 1] - wcss[i]
      const nextImprovement = wcss[i] - wcss[i + 1]
      
      // ê°œì„  ì •ë„ê°€ ê¸‰ê²©íˆ ê°ì†Œí•˜ëŠ” ì§€ì  ì°¾ê¸°
      if (improvement > nextImprovement * 1.5 && improvement > maxImprovement) {
        maxImprovement = improvement
        optimalK = i + 1
      }
    }
  }
  
  return Math.max(2, Math.min(optimalK, actualMaxK))
} 